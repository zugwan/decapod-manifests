# Source: nova/templates/configmap-bin.yaml
apiVersion: v1
kind: ConfigMap
metadata:
  name: nova-bin
data:
  bootstrap.sh: |
    #!/bin/bash
    
    
    
    set -ex
    export HOME=/tmp
    
    
    
    openstack flavor show m1.large || \
     openstack flavor create m1.large \
     --id auto \
     --ram 8192 \
     --disk 80 \
     --vcpus 4
    
    openstack flavor show m1.medium || \
     openstack flavor create m1.medium \
     --id auto \
     --ram 4096 \
     --disk 40 \
     --vcpus 2
    
    openstack flavor show m1.small || \
     openstack flavor create m1.small \
     --id auto \
     --ram 2048 \
     --disk 20 \
     --vcpus 1
    
    openstack flavor show m1.tiny || \
     openstack flavor create m1.tiny \
     --id 0c84e220-a258-439f-a6ff-f8e9fd980025 \
     --ram 512 \
     --disk 1 \
     --vcpus 1
    
    openstack flavor show m1.xlarge || \
     openstack flavor create m1.xlarge \
     --id auto \
     --ram 16384 \
     --disk 160 \
     --vcpus 8
    
    
    
    
    echo 'Wait for Computes script not enabled'
    
    
    echo 'No other bootstrap customizations found.'
    
  rally-test.sh: |
    #!/bin/bash
    set -ex
    
    : "${RALLY_ENV_NAME:="openstack-helm"}"
    : "${OS_INTERFACE:="public"}"
    : "${RALLY_CLEANUP:="true"}"
    
    if [ "x$RALLY_CLEANUP" == "xtrue" ]; then
      function rally_cleanup {
        openstack user delete \
            --domain="${SERVICE_OS_USER_DOMAIN_NAME}" \
            "${SERVICE_OS_USERNAME}"
        FLAVORS=$(openstack flavor list -f value | grep -e "^s_rally_" | awk '{ print $1 }')
        if [ -n "$FLAVORS" ]; then
          echo $FLAVORS | xargs openstack flavor delete
        fi
        SERVERS=$(openstack server list -f value | grep -e "^s_rally_" | awk '{ print $1 }')
        if [ -n "$SERVERS" ]; then
          echo $SERVERS | xargs openstack server delete
        fi
        
      }
      trap rally_cleanup EXIT
    fi
    
    function create_or_update_db () {
      revisionResults=$(rally db revision)
      if [ $revisionResults = "None"  ]
      then
        rally db create
      else
        rally db upgrade
      fi
    }
    
    create_or_update_db
    
    cat > /tmp/rally-config.json << EOF
    {
        "openstack": {
            "auth_url": "${OS_AUTH_URL}",
            "region_name": "${OS_REGION_NAME}",
            "endpoint_type": "${OS_INTERFACE}",
            "admin": {
                "username": "${OS_USERNAME}",
                "password": "${OS_PASSWORD}",
                "user_domain_name": "${OS_USER_DOMAIN_NAME}",
                "project_name": "${OS_PROJECT_NAME}",
                "project_domain_name": "${OS_PROJECT_DOMAIN_NAME}"
            },
            "users": [
                {
                    "username": "${SERVICE_OS_USERNAME}",
                    "password": "${SERVICE_OS_PASSWORD}",
                    "project_name": "${SERVICE_OS_PROJECT_NAME}",
                    "user_domain_name": "${SERVICE_OS_USER_DOMAIN_NAME}",
                    "project_domain_name": "${SERVICE_OS_PROJECT_DOMAIN_NAME}"
                }
            ],
            "https_insecure": false,
            "https_cacert": "${OS_CACERT}"
        }
    }
    EOF
    rally deployment create --file /tmp/rally-config.json --name "${RALLY_ENV_NAME}"
    rm -f /tmp/rally-config.json
    rally deployment use "${RALLY_ENV_NAME}"
    rally deployment check
    rally task validate /etc/rally/rally_tests.yaml
    rally task start /etc/rally/rally_tests.yaml
    rally task sla-check
    rally env cleanup
    rally deployment destroy --deployment "${RALLY_ENV_NAME}"
  db-init.py: |    
    #!/usr/bin/env python
    
    # Creates db and user for an OpenStack Service:
    # Set ROOT_DB_CONNECTION and DB_CONNECTION environment variables to contain
    # SQLAlchemy strings for the root connection to the database and the one you
    # wish the service to use. Alternatively, you can use an ini formatted config
    # at the location specified by OPENSTACK_CONFIG_FILE, and extract the string
    # from the key OPENSTACK_CONFIG_DB_KEY, in the section specified by
    # OPENSTACK_CONFIG_DB_SECTION.
    
    import os
    import sys
    try:
        import ConfigParser
        PARSER_OPTS = {}
    except ImportError:
        import configparser as ConfigParser
        PARSER_OPTS = {"strict": False}
    import logging
    from sqlalchemy import create_engine
    
    # Create logger, console handler and formatter
    logger = logging.getLogger('OpenStack-Helm DB Init')
    logger.setLevel(logging.DEBUG)
    ch = logging.StreamHandler()
    ch.setLevel(logging.DEBUG)
    formatter = logging.Formatter('%(asctime)s - %(name)s - %(levelname)s - %(message)s')
    
    # Set the formatter and add the handler
    ch.setFormatter(formatter)
    logger.addHandler(ch)
    
    
    # Get the connection string for the service db root user
    if "ROOT_DB_CONNECTION" in os.environ:
        db_connection = os.environ['ROOT_DB_CONNECTION']
        logger.info('Got DB root connection')
    else:
        logger.critical('environment variable ROOT_DB_CONNECTION not set')
        sys.exit(1)
    
    mysql_x509 = os.getenv('MARIADB_X509', "")
    ssl_args = {}
    if mysql_x509:
        ssl_args = {'ssl': {'ca': '/etc/mysql/certs/ca.crt',
                    'key': '/etc/mysql/certs/tls.key',
                    'cert': '/etc/mysql/certs/tls.crt'}}
    
    # Get the connection string for the service db
    if "OPENSTACK_CONFIG_FILE" in os.environ:
        os_conf = os.environ['OPENSTACK_CONFIG_FILE']
        if "OPENSTACK_CONFIG_DB_SECTION" in os.environ:
            os_conf_section = os.environ['OPENSTACK_CONFIG_DB_SECTION']
        else:
            logger.critical('environment variable OPENSTACK_CONFIG_DB_SECTION not set')
            sys.exit(1)
        if "OPENSTACK_CONFIG_DB_KEY" in os.environ:
            os_conf_key = os.environ['OPENSTACK_CONFIG_DB_KEY']
        else:
            logger.critical('environment variable OPENSTACK_CONFIG_DB_KEY not set')
            sys.exit(1)
        try:
            config = ConfigParser.RawConfigParser(**PARSER_OPTS)
            logger.info("Using {0} as db config source".format(os_conf))
            config.read(os_conf)
            logger.info("Trying to load db config from {0}:{1}".format(
                os_conf_section, os_conf_key))
            user_db_conn = config.get(os_conf_section, os_conf_key)
            logger.info("Got config from {0}".format(os_conf))
        except:
            logger.critical("Tried to load config from {0} but failed.".format(os_conf))
            raise
    elif "DB_CONNECTION" in os.environ:
        user_db_conn = os.environ['DB_CONNECTION']
        logger.info('Got config from DB_CONNECTION env var')
    else:
        logger.critical('Could not get db config, either from config file or env var')
        sys.exit(1)
    
    # Root DB engine
    try:
        root_engine_full = create_engine(db_connection)
        root_user = root_engine_full.url.username
        root_password = root_engine_full.url.password
        drivername = root_engine_full.url.drivername
        host = root_engine_full.url.host
        port = root_engine_full.url.port
        root_engine_url = ''.join([drivername, '://', root_user, ':', root_password, '@', host, ':', str (port)])
        root_engine = create_engine(root_engine_url, connect_args=ssl_args)
        connection = root_engine.connect()
        connection.close()
        logger.info("Tested connection to DB @ {0}:{1} as {2}".format(
            host, port, root_user))
    except:
        logger.critical('Could not connect to database as root user')
        raise
    
    # User DB engine
    try:
        user_engine = create_engine(user_db_conn, connect_args=ssl_args)
        # Get our user data out of the user_engine
        database = user_engine.url.database
        user = user_engine.url.username
        password = user_engine.url.password
        logger.info('Got user db config')
    except:
        logger.critical('Could not get user database config')
        raise
    
    # Create DB
    try:
        root_engine.execute("CREATE DATABASE IF NOT EXISTS {0}".format(database))
        logger.info("Created database {0}".format(database))
    except:
        logger.critical("Could not create database {0}".format(database))
        raise
    
    # Create DB User
    try:
        root_engine.execute(
            "GRANT ALL ON `{0}`.* TO \'{1}\'@\'%%\' IDENTIFIED BY \'{2}\' {3}".format(
                database, user, password, mysql_x509))
        logger.info("Created user {0} for {1}".format(user, database))
    except:
        logger.critical("Could not create user {0} for {1}".format(user, database))
        raise
    
    # Test connection
    try:
        connection = user_engine.connect()
        connection.close()
        logger.info("Tested connection to DB @ {0}:{1}/{2} as {3}".format(
            host, port, database, user))
    except:
        logger.critical('Could not connect to database as user')
        raise
    
    logger.info('Finished DB Management')
  db-sync.sh: |
    #!/bin/bash
    
    
    
    set -ex
    NOVA_VERSION=$(nova-manage --version 2>&1| grep -Eo '[0-9]+[.][0-9]+[.][0-9]+')
    
    function manage_cells () {
      # NOTE(portdirect): check if nova fully supports cells v2, and manage
      # accordingly. Support was complete in ocata (V14.x.x).
      if [ "${NOVA_VERSION%%.*}" -gt "14" ]; then
        nova-manage cell_v2 map_cell0
        nova-manage cell_v2 list_cells | grep -q " cell1 " || \
          nova-manage cell_v2 create_cell --name=cell1 --verbose
    
        CELL1_ID=$(nova-manage cell_v2 list_cells | awk -F '|' '/ cell1 / { print $3 }' | tr -d ' ')
        set +x
        for VAR in TRANSPORT_URL DB_CONNECTION; do
          if [ -z "${!VAR}" ]; then
            echo "ERROR: missing $VAR variable"
            exit 1
          fi
        done
        nova-manage cell_v2 update_cell \
          --cell_uuid="${CELL1_ID}" \
          --name="cell1" \
          --transport-url="${TRANSPORT_URL}" \
          --database_connection="${DB_CONNECTION}"
        set -x
      fi
    }
    
    # NOTE(portdirect): if the db has been populated we should setup cells if
    # required, otherwise we should poulate the api db, and then setup cells.
    if [ "$(nova-manage api_db version)" -gt "0" ]; then
      manage_cells
      nova-manage api_db sync
    else
      nova-manage api_db sync
      manage_cells
    fi
    
    nova-manage db sync
    
    nova-manage db online_data_migrations
    
    echo 'Finished DB migrations'
    
  db-drop.py: |    
    #!/usr/bin/env python
    
    # Drops db and user for an OpenStack Service:
    # Set ROOT_DB_CONNECTION and DB_CONNECTION environment variables to contain
    # SQLAlchemy strings for the root connection to the database and the one you
    # wish the service to use. Alternatively, you can use an ini formatted config
    # at the location specified by OPENSTACK_CONFIG_FILE, and extract the string
    # from the key OPENSTACK_CONFIG_DB_KEY, in the section specified by
    # OPENSTACK_CONFIG_DB_SECTION.
    
    import os
    import sys
    try:
        import ConfigParser
        PARSER_OPTS = {}
    except ImportError:
        import configparser as ConfigParser
        PARSER_OPTS = {"strict": False}
    import logging
    from sqlalchemy import create_engine
    
    # Create logger, console handler and formatter
    logger = logging.getLogger('OpenStack-Helm DB Drop')
    logger.setLevel(logging.DEBUG)
    ch = logging.StreamHandler()
    ch.setLevel(logging.DEBUG)
    formatter = logging.Formatter('%(asctime)s - %(name)s - %(levelname)s - %(message)s')
    
    # Set the formatter and add the handler
    ch.setFormatter(formatter)
    logger.addHandler(ch)
    
    
    # Get the connection string for the service db root user
    if "ROOT_DB_CONNECTION" in os.environ:
        db_connection = os.environ['ROOT_DB_CONNECTION']
        logger.info('Got DB root connection')
    else:
        logger.critical('environment variable ROOT_DB_CONNECTION not set')
        sys.exit(1)
    
    mysql_x509 = os.getenv('MARIADB_X509', "")
    ssl_args = {}
    if mysql_x509:
        ssl_args = {'ssl': {'ca': '/etc/mysql/certs/ca.crt',
                            'key': '/etc/mysql/certs/tls.key',
                            'cert': '/etc/mysql/certs/tls.crt'}}
    
    # Get the connection string for the service db
    if "OPENSTACK_CONFIG_FILE" in os.environ:
        os_conf = os.environ['OPENSTACK_CONFIG_FILE']
        if "OPENSTACK_CONFIG_DB_SECTION" in os.environ:
            os_conf_section = os.environ['OPENSTACK_CONFIG_DB_SECTION']
        else:
            logger.critical('environment variable OPENSTACK_CONFIG_DB_SECTION not set')
            sys.exit(1)
        if "OPENSTACK_CONFIG_DB_KEY" in os.environ:
            os_conf_key = os.environ['OPENSTACK_CONFIG_DB_KEY']
        else:
            logger.critical('environment variable OPENSTACK_CONFIG_DB_KEY not set')
            sys.exit(1)
        try:
            config = ConfigParser.RawConfigParser(**PARSER_OPTS)
            logger.info("Using {0} as db config source".format(os_conf))
            config.read(os_conf)
            logger.info("Trying to load db config from {0}:{1}".format(
                os_conf_section, os_conf_key))
            user_db_conn = config.get(os_conf_section, os_conf_key)
            logger.info("Got config from {0}".format(os_conf))
        except:
            logger.critical("Tried to load config from {0} but failed.".format(os_conf))
            raise
    elif "DB_CONNECTION" in os.environ:
        user_db_conn = os.environ['DB_CONNECTION']
        logger.info('Got config from DB_CONNECTION env var')
    else:
        logger.critical('Could not get db config, either from config file or env var')
        sys.exit(1)
    
    # Root DB engine
    try:
        root_engine_full = create_engine(db_connection)
        root_user = root_engine_full.url.username
        root_password = root_engine_full.url.password
        drivername = root_engine_full.url.drivername
        host = root_engine_full.url.host
        port = root_engine_full.url.port
        root_engine_url = ''.join([drivername, '://', root_user, ':', root_password, '@', host, ':', str (port)])
        root_engine = create_engine(root_engine_url, connect_args=ssl_args)
        connection = root_engine.connect()
        connection.close()
        logger.info("Tested connection to DB @ {0}:{1} as {2}".format(
            host, port, root_user))
    except:
        logger.critical('Could not connect to database as root user')
        raise
    
    # User DB engine
    try:
        user_engine = create_engine(user_db_conn, connect_args=ssl_args)
        # Get our user data out of the user_engine
        database = user_engine.url.database
        user = user_engine.url.username
        password = user_engine.url.password
        logger.info('Got user db config')
    except:
        logger.critical('Could not get user database config')
        raise
    
    # Delete DB
    try:
        root_engine.execute("DROP DATABASE IF EXISTS {0}".format(database))
        logger.info("Deleted database {0}".format(database))
    except:
        logger.critical("Could not drop database {0}".format(database))
        raise
    
    # Delete DB User
    try:
        root_engine.execute("DROP USER IF EXISTS {0}".format(user))
        logger.info("Deleted user {0}".format(user))
    except:
        logger.critical("Could not delete user {0}".format(user))
        raise
    
    logger.info('Finished DB Management')
  ks-service.sh: |    
    #!/bin/bash
    
    # Copyright 2017 Pete Birley
    #
    # Licensed under the Apache License, Version 2.0 (the "License");
    # you may not use this file except in compliance with the License.
    # You may obtain a copy of the License at
    #
    # http://www.apache.org/licenses/LICENSE-2.0
    #
    # Unless required by applicable law or agreed to in writing, software
    # distributed under the License is distributed on an "AS IS" BASIS,
    # WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
    # See the License for the specific language governing permissions and
    # limitations under the License.
    
    set -ex
    
    # Service boilerplate description
    OS_SERVICE_DESC="${OS_REGION_NAME}: ${OS_SERVICE_NAME} (${OS_SERVICE_TYPE}) service"
    
    # Get Service ID if it exists
    unset OS_SERVICE_ID
    OS_SERVICE_ID=$( openstack service list -f csv --quote none | \
                     grep ",${OS_SERVICE_NAME},${OS_SERVICE_TYPE}$" | \
                     sed -e "s/,${OS_SERVICE_NAME},${OS_SERVICE_TYPE}//g" )
    
    # If a Service ID was not found, then create the service
    if [[ -z ${OS_SERVICE_ID} ]]; then
      OS_SERVICE_ID=$(openstack service create -f value -c id \
                      --name="${OS_SERVICE_NAME}" \
                      --description "${OS_SERVICE_DESC}" \
                      --enable \
                      "${OS_SERVICE_TYPE}")
    fi
  ks-endpoints.sh: |    
    #!/bin/bash
    
    # Copyright 2017 Pete Birley
    #
    # Licensed under the Apache License, Version 2.0 (the "License");
    # you may not use this file except in compliance with the License.
    # You may obtain a copy of the License at
    #
    # http://www.apache.org/licenses/LICENSE-2.0
    #
    # Unless required by applicable law or agreed to in writing, software
    # distributed under the License is distributed on an "AS IS" BASIS,
    # WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
    # See the License for the specific language governing permissions and
    # limitations under the License.
    
    set -ex
    
    # Get Service ID
    OS_SERVICE_ID=$( openstack service list -f csv --quote none | \
                      grep ",${OS_SERVICE_NAME},${OS_SERVICE_TYPE}$" | \
                        sed -e "s/,${OS_SERVICE_NAME},${OS_SERVICE_TYPE}//g" )
    
    # Get Endpoint ID if it exists
    OS_ENDPOINT_ID=$( openstack endpoint list  -f csv --quote none | \
                      grep "^[a-z0-9]*,${OS_REGION_NAME},${OS_SERVICE_NAME},${OS_SERVICE_TYPE},True,${OS_SVC_ENDPOINT}," | \
                      awk -F ',' '{ print $1 }' )
    
    # Making sure only a single endpoint exists for a service within a region
    if [ "$(echo $OS_ENDPOINT_ID | wc -w)" -gt "1" ]; then
      echo "More than one endpoint found, cleaning up"
      for ENDPOINT_ID in $OS_ENDPOINT_ID; do
        openstack endpoint delete ${ENDPOINT_ID}
      done
      unset OS_ENDPOINT_ID
    fi
    
    # Determine if Endpoint needs updated
    if [[ ${OS_ENDPOINT_ID} ]]; then
      OS_ENDPOINT_URL_CURRENT=$(openstack endpoint show ${OS_ENDPOINT_ID} -f value -c url)
      if [ "${OS_ENDPOINT_URL_CURRENT}" == "${OS_SERVICE_ENDPOINT}" ]; then
        echo "Endpoints Match: no action required"
        OS_ENDPOINT_UPDATE="False"
      else
        echo "Endpoints Dont Match: removing existing entries"
        openstack endpoint delete ${OS_ENDPOINT_ID}
        OS_ENDPOINT_UPDATE="True"
      fi
    else
      OS_ENDPOINT_UPDATE="True"
    fi
    
    # Update Endpoint if required
    if [[ "${OS_ENDPOINT_UPDATE}" == "True" ]]; then
      OS_ENDPOINT_ID=$( openstack endpoint create -f value -c id \
        --region="${OS_REGION_NAME}" \
        "${OS_SERVICE_ID}" \
        ${OS_SVC_ENDPOINT} \
        "${OS_SERVICE_ENDPOINT}" )
    fi
    
    # Display the Endpoint
    openstack endpoint show ${OS_ENDPOINT_ID}
  ks-user.sh: |    
    #!/bin/bash
    
    # Copyright 2017 Pete Birley
    #
    # Licensed under the Apache License, Version 2.0 (the "License");
    # you may not use this file except in compliance with the License.
    # You may obtain a copy of the License at
    #
    # http://www.apache.org/licenses/LICENSE-2.0
    #
    # Unless required by applicable law or agreed to in writing, software
    # distributed under the License is distributed on an "AS IS" BASIS,
    # WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
    # See the License for the specific language governing permissions and
    # limitations under the License.
    
    set -ex
    
    if [[ "${SERVICE_OS_PROJECT_DOMAIN_NAME}" == "Default" ]]
    then
      PROJECT_DOMAIN_ID="default"
    else
      # Manage project domain
      PROJECT_DOMAIN_ID=$(openstack domain create --or-show --enable -f value -c id \
        --description="Domain for ${SERVICE_OS_REGION_NAME}/${SERVICE_OS_PROJECT_DOMAIN_NAME}" \
        "${SERVICE_OS_PROJECT_DOMAIN_NAME}")
    fi
    
    if [[ "${SERVICE_OS_USER_DOMAIN_NAME}" == "Default" ]]
    then
      USER_DOMAIN_ID="default"
    else
      # Manage user domain
      USER_DOMAIN_ID=$(openstack domain create --or-show --enable -f value -c id \
        --description="Domain for ${SERVICE_OS_REGION_NAME}/${SERVICE_OS_USER_DOMAIN_NAME}" \
        "${SERVICE_OS_USER_DOMAIN_NAME}")
    fi
    
    # Manage user project
    USER_PROJECT_DESC="Service Project for ${SERVICE_OS_REGION_NAME}/${SERVICE_OS_PROJECT_DOMAIN_NAME}"
    USER_PROJECT_ID=$(openstack project create --or-show --enable -f value -c id \
        --domain="${PROJECT_DOMAIN_ID}" \
        --description="${USER_PROJECT_DESC}" \
        "${SERVICE_OS_PROJECT_NAME}");
    
    # Manage user
    USER_DESC="Service User for ${SERVICE_OS_REGION_NAME}/${SERVICE_OS_USER_DOMAIN_NAME}/${SERVICE_OS_SERVICE_NAME}"
    USER_ID=$(openstack user create --or-show --enable -f value -c id \
        --domain="${USER_DOMAIN_ID}" \
        --project-domain="${PROJECT_DOMAIN_ID}" \
        --project="${USER_PROJECT_ID}" \
        --description="${USER_DESC}" \
        "${SERVICE_OS_USERNAME}");
    
    # Manage user password (we do this in a seperate step to ensure the password is updated if required)
    set +x
    echo "Setting user password via: openstack user set --password=xxxxxxx ${USER_ID}"
    openstack user set --password="${SERVICE_OS_PASSWORD}" "${USER_ID}"
    set -x
    
    function ks_assign_user_role () {
      if [[ "$SERVICE_OS_ROLE" == "admin" ]]
      then
        USER_ROLE_ID="$SERVICE_OS_ROLE"
      else
        USER_ROLE_ID=$(openstack role create --or-show -f value -c id "${SERVICE_OS_ROLE}");
      fi
    
      # Manage user role assignment
      openstack role add \
          --user="${USER_ID}" \
          --user-domain="${USER_DOMAIN_ID}" \
          --project-domain="${PROJECT_DOMAIN_ID}" \
          --project="${USER_PROJECT_ID}" \
          "${USER_ROLE_ID}"
    }
    
    # Manage user service role
    IFS=','
    for SERVICE_OS_ROLE in ${SERVICE_OS_ROLES}; do
      ks_assign_user_role
    done
    
    # Manage user member role
    : ${MEMBER_OS_ROLE:="member"}
    export USER_ROLE_ID=$(openstack role create --or-show -f value -c id \
        "${MEMBER_OS_ROLE}");
    ks_assign_user_role
  ceph-keyring.sh: |
    #!/bin/bash
    
    
    
    set -ex
    export HOME=/tmp
    
    cp -vf /etc/ceph/ceph.conf.template /etc/ceph/ceph.conf
    
    KEYRING=/etc/ceph/ceph.client.${CEPH_CINDER_USER}.keyring
    cat > ${KEYRING} <<EOF
    [client.cinder]
        key = AQAin8tU0CFgEhAATb7sYgtWsh+S5HEbg6MrGg==
    EOF
    
  ceph-admin-keyring.sh: |
    #!/bin/bash
    
    
    
    set -ex
    export HOME=/tmp
    
    cat > /etc/ceph/ceph.client.admin.keyring << EOF
    [client.admin]
        key = AQBAHAdfHQ5RLhAAzynxAYUokA55ku4ZwqVJjQ==
    EOF
    
    exit 0
    
  health-probe.py: |
    #!/usr/bin/env python
    
    # Copyright 2019 The Openstack-Helm Authors.
    #
    # Licensed under the Apache License, Version 2.0 (the "License");
    # you may not use this file except in compliance with the License.
    # You may obtain a copy of the License at
    #
    #     http://www.apache.org/licenses/LICENSE-2.0
    #
    # Unless required by applicable law or agreed to in writing, software
    # distributed under the License is distributed on an "AS IS" BASIS,
    # WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
    # See the License for the specific language governing permissions and
    # limitations under the License.
    
    """
    Health probe script for OpenStack service that uses RPC/unix domain socket for
    communication. Check's the RPC tcp socket status on the process and send
    message to service through rpc call method and expects a reply.
    Use nova's ping method that is designed just for such simple purpose.
    
    Script returns failure to Kubernetes only when
      a. TCP socket for the RPC communication are not established.
      b. service is not reachable or
      c. service times out sending a reply.
    
    sys.stderr.write() writes to pod's events on failures.
    
    Usage example for Nova Compute:
    # python health-probe.py --config-file /etc/nova/nova.conf \
    #  --service-queue-name compute
    
    """
    
    import psutil
    import socket
    import sys
    
    from oslo_config import cfg
    from oslo_context import context
    from oslo_log import log
    import oslo_messaging
    
    
    tcp_established = "ESTABLISHED"
    
    
    def _get_hostname(topic, use_fqdn):
        if use_fqdn and topic == "compute":
            return socket.getfqdn()
        return socket.gethostname()
    
    
    def check_service_status(transport):
        """Verify service status. Return success if service consumes message"""
        try:
            service_queue_name = cfg.CONF.service_queue_name
            use_fqdn = cfg.CONF.use_fqdn
            target = oslo_messaging.Target(
                topic=service_queue_name,
                server=_get_hostname(service_queue_name, use_fqdn),
                namespace='baseapi',
                version="1.1")
            client = oslo_messaging.RPCClient(transport, target,
                                              timeout=60,
                                              retry=2)
            client.call(context.RequestContext(),
                        'ping',
                        arg=None)
        except oslo_messaging.exceptions.MessageDeliveryFailure:
            # Log to pod events
            sys.stderr.write("Health probe unable to reach message bus")
            sys.exit(0)  # return success
        except oslo_messaging.rpc.client.RemoteError as re:
            message = getattr(re, "message", str(re))
            if ("Endpoint does not support RPC method" in message) or \
                    ("Endpoint does not support RPC version" in message):
                sys.exit(0)  # Call reached the service
            else:
                sys.stderr.write("Health probe unable to reach service")
                sys.exit(1)  # return failure
        except oslo_messaging.exceptions.MessagingTimeout:
            sys.stderr.write("Health probe timed out. Agent is down or response "
                             "timed out")
            sys.exit(1)  # return failure
        except Exception as ex:
            message = getattr(ex, "message", str(ex))
            sys.stderr.write("Health probe caught exception sending message to "
                             "service: %s" % message)
            sys.exit(0)
        except:
            sys.stderr.write("Health probe caught exception sending message to"
                             " service")
            sys.exit(0)
    
    
    def tcp_socket_status(process, ports):
        """Check the tcp socket status on a process"""
        for p in psutil.process_iter():
            try:
                with p.oneshot():
                    if process in " ".join(p.cmdline()):
                        pcon = p.connections()
                        for con in pcon:
                            try:
                                rport = con.raddr[1]
                                status = con.status
                            except IndexError:
                                continue
                            if rport in ports and status == tcp_established:
                                return 1
            except psutil.Error:
                continue
        return 0
    
    
    def configured_port_in_conf():
        """Get the rabbitmq/Database port configured in config file"""
    
        rabbit_ports = set()
        database_ports = set()
    
        try:
            transport_url = oslo_messaging.TransportURL.parse(cfg.CONF)
            for host in transport_url.hosts:
                rabbit_ports.add(host.port)
        except Exception as ex:
            message = getattr(ex, "message", str(ex))
            sys.stderr.write("Health probe caught exception reading "
                             "RabbitMQ ports: %s" % message)
            sys.exit(0)  # return success
    
        try:
            with open(sys.argv[2]) as conf_file:
                for line in conf_file:
                    if "connection =" in line:
                        service = line.split(':', 3)[3].split('/')[1].rstrip('\n')
                        if service == "nova":
                            database_ports.add(
                                int(line.split(':', 3)[3].split('/')[0]))
        except IOError:
            sys.stderr.write("Nova Config file not present")
            sys.exit(1)
    
        return rabbit_ports, database_ports
    
    
    def test_tcp_socket(service):
        """Check tcp socket to rabbitmq/db is in Established state"""
        dict_services = {
            "compute": "nova-compute",
            "conductor": "nova-conductor",
            "consoleauth": "nova-consoleaut",
            "scheduler": "nova-scheduler"
        }
        r_ports, d_ports = configured_port_in_conf()
    
        if service in dict_services:
            proc = dict_services[service]
            if r_ports and tcp_socket_status(proc, r_ports) == 0:
                sys.stderr.write("RabbitMQ socket not established")
                # Do not kill the pod if RabbitMQ is not reachable/down
                if not cfg.CONF.liveness_probe:
                    sys.exit(1)
    
            # let's do the db check
            if service != "compute":
                if d_ports and tcp_socket_status(proc, d_ports) == 0:
                    sys.stderr.write("Database socket not established")
                    # Do not kill the pod if database is not reachable/down
                    # there could be no socket as well as typically connections
                    # get closed after an idle timeout
                    # Just log it to pod events
                    if not cfg.CONF.liveness_probe:
                        sys.exit(1)
    
    
    def test_rpc_liveness():
        """Test if service can consume message from queue"""
        oslo_messaging.set_transport_defaults(control_exchange='nova')
    
        rabbit_group = cfg.OptGroup(name='oslo_messaging_rabbit',
                                    title='RabbitMQ options')
        cfg.CONF.register_group(rabbit_group)
        cfg.CONF.register_cli_opt(cfg.StrOpt('service-queue-name'))
        cfg.CONF.register_cli_opt(cfg.BoolOpt('liveness-probe', default=False,
                                              required=False))
        cfg.CONF.register_cli_opt(cfg.BoolOpt('use-fqdn', default=False,
                                              required=False))
    
        cfg.CONF(sys.argv[1:])
    
        log.logging.basicConfig(level=log.ERROR)
    
        try:
            transport = oslo_messaging.get_transport(cfg.CONF)
        except Exception as ex:
            message = getattr(ex, "message", str(ex))
            sys.stderr.write("Message bus driver load error: %s" % message)
            sys.exit(0)  # return success
    
        if not cfg.CONF.transport_url or \
                not cfg.CONF.service_queue_name:
            sys.stderr.write("Both message bus URL and service's queue name are "
                             "required for health probe to work")
            sys.exit(0)  # return success
    
        try:
            cfg.CONF.set_override('rabbit_max_retries', 2,
                                  group=rabbit_group)  # 3 attempts
        except cfg.NoSuchOptError as ex:
            cfg.CONF.register_opt(cfg.IntOpt('rabbit_max_retries', default=2),
                                  group=rabbit_group)
    
        service = cfg.CONF.service_queue_name
        test_tcp_socket(service)
    
        check_service_status(transport)
    
    
    if __name__ == "__main__":
        test_rpc_liveness()
    
        sys.exit(0)  # return success
    
  nova-api.sh: |
    #!/bin/bash
    
    
    
    set -ex
    COMMAND="${@:-start}"
    
    function start () {
      exec nova-api-os-compute \
            --config-file /etc/nova/nova.conf
    }
    
    function stop () {
      kill -TERM 1
    }
    
    $COMMAND
    
  nova-api-metadata.sh: |
    #!/bin/bash
    
    
    
    set -ex
    COMMAND="${@:-start}"
    
    function start () {
      exec nova-api-metadata \
            --config-file /etc/nova/nova.conf \
            --config-file /tmp/pod-shared/nova-api-metadata.ini
    }
    
    function stop () {
      kill -TERM 1
    }
    
    $COMMAND
    
  nova-api-metadata-init.sh: |
    #!/bin/bash
    
    
    
    set -ex
    
    metadata_ip=""
    if [ -z "${metadata_ip}" ] ; then
        metadata_ip=$(getent hosts metadata | awk '{print $1}')
    fi
    
    cat <<EOF>/tmp/pod-shared/nova-api-metadata.ini
    [DEFAULT]
    metadata_host=$metadata_ip
    EOF
    
  nova-placement-api.sh: |
    #!/bin/bash
    
    
    
    set -ex
    COMMAND="${@:-start}"
    
    function start () {
    
      cp -a $(type -p nova-placement-api) /var/www/cgi-bin/nova/
    
      if [ -f /etc/apache2/envvars ]; then
         # Loading Apache2 ENV variables
         source /etc/apache2/envvars
         # The directory below has to be created due to the fact that
         # libapache2-mod-wsgi-py3 doesn't create it in contrary by libapache2-mod-wsgi
         if [ ! -d ${APACHE_RUN_DIR} ]; then
            mkdir -p ${APACHE_RUN_DIR}
         fi
      fi
    
      # Start Apache2
      exec apache2 -DFOREGROUND
    }
    
    function stop () {
      apache2 -k graceful-stop
    }
    
    $COMMAND
    
  nova-compute.sh: |
    #!/bin/bash
    
    
    
    set -ex
    
    exec nova-compute \
          --config-file /etc/nova/nova.conf \
          --config-file /tmp/pod-shared/nova-console.conf \
          --config-file /tmp/pod-shared/nova-libvirt.conf \
          --config-file /tmp/pod-shared/nova-compute-fqdn.conf \
          --config-file /tmp/pod-shared/nova-hypervisor.conf
    
  nova-compute-init.sh: |
    #!/bin/bash
    
    
    
    set -ex
    
    # Make the Nova Instances Dir as this is not autocreated.
    mkdir -p /var/lib/nova/instances
    
    # Set Ownership of nova dirs to the nova user
    chown ${NOVA_USER_UID} /var/lib/nova /var/lib/nova/instances
    
    migration_interface="eth0"
    if [[ -n $migration_interface ]]; then
        # determine ip dynamically based on interface provided
        migration_address=$(ip a s $migration_interface | grep 'inet ' | awk '{print $2}' | awk -F "/" '{print $1}')
    fi
    
    touch /tmp/pod-shared/nova-libvirt.conf
    if [[ -n $migration_address ]]; then
    cat <<EOF>/tmp/pod-shared/nova-libvirt.conf
    [libvirt]
    live_migration_inbound_addr = $migration_address
    EOF
    fi
    
    hypervisor_interface="eth0"
    if [[ -z $hypervisor_interface ]]; then
        # search for interface with default routing
        # If there is not default gateway, exit
        hypervisor_interface=$(ip -4 route list 0/0 | awk -F 'dev' '{ print $2; exit }' | awk '{ print $1 }') || exit 1
    fi
    
    hypervisor_address=$(ip a s $hypervisor_interface | grep 'inet ' | awk '{print $2}' | awk -F "/" '{print $1}')
    
    if [ -z "${hypervisor_address}" ] ; then
      echo "Var my_ip is empty"
      exit 1
    fi
    
    tee > /tmp/pod-shared/nova-hypervisor.conf << EOF
    [DEFAULT]
    my_ip  = $hypervisor_address
    EOF
    tee > /tmp/pod-shared/nova-compute-fqdn.conf << EOF
    [DEFAULT]
    host = $(hostname --fqdn)
    EOF
    
  nova-compute-ironic.sh: |
    #!/bin/bash
    
    
    
    set -ex
    
    exec nova-compute \
          --config-file /etc/nova/nova.conf \
          --config-file /etc/nova/nova-ironic.conf
    
  nova-conductor.sh: |
    #!/bin/bash
    
    
    
    set -x
    exec nova-conductor \
          --config-file /etc/nova/nova.conf
    
  nova-consoleauth.sh: |
    #!/bin/bash
    
    
    
    set -x
    exec nova-consoleauth \
          --config-file /etc/nova/nova.conf
    
  nova-scheduler.sh: |
    #!/bin/bash
    
    
    
    set -xe
    
    exec nova-scheduler \
          --config-file /etc/nova/nova.conf
    
  fake-iptables.sh: |
    #!/bin/bash
    
    
    
    exit 0
    
  nova-console-compute-init.sh: |
    #!/bin/bash
    
    
    
    set -ex
    
    console_kind="novnc"
    
    if [ "${console_kind}" == "novnc" ] ; then
        client_address=""
        client_interface=""
        listen_ip=""
    elif [ "${console_kind}" == "spice" ] ; then
        client_address=""
        client_interface=""
        listen_ip="0.0.0.0"
    fi
    
    if [ -z "${client_address}" ] ; then
        if [ -z "${client_interface}" ] ; then
            # search for interface with default routing, if multiple default routes exist then select the one with the lowest metric.
            client_interface=$(route -n | awk '/^0.0.0.0/ { print $5 " " $NF }' | sort | awk '{ print $NF; exit }')
        fi
    
        # determine client ip dynamically based on interface provided
        client_address=$(ip a s $client_interface | grep 'inet ' | awk '{print $2}' | awk -F "/" '{print $1}' | head -n 1)
    fi
    
    if [ -z "${listen_ip}" ] ; then
        # The server component listens on all IP addresses and the proxy component
        # only listens on the management interface IP address of the compute node.
        listen_ip=0.0.0.0
    fi
    
    touch /tmp/pod-shared/nova-console.conf
    if [ "${console_kind}" == "novnc" ] ; then
      cat > /tmp/pod-shared/nova-console.conf <<EOF
    [vnc]
    vncserver_proxyclient_address = $client_address
    vncserver_listen = $listen_ip
    EOF
    elif [ "${console_kind}" == "spice" ] ; then
      cat > /tmp/pod-shared/nova-console.conf <<EOF
    [spice]
    server_proxyclient_address = $client_address
    server_listen = $listen_ip
    EOF
    fi
    
  nova-console-proxy.sh: |
    #!/bin/bash
    
    
    
    set -x
    
    console_kind="novnc"
    if [ "${console_kind}" == "novnc" ] ; then
        exec nova-novncproxy \
            --config-file /etc/nova/nova.conf \
            --config-file /tmp/pod-shared/nova-vnc.ini
    elif [ "${console_kind}" == "spice" ] ; then
        exec nova-spicehtml5proxy\
            --config-file /etc/nova/nova.conf \
            --config-file /tmp/pod-shared/nova-spice.ini
    fi
  nova-console-proxy-init.sh: |
    #!/bin/bash
    
    
    
    set -ex
    
    console_kind="novnc"
    
    if [ "${console_kind}" == "novnc" ] ; then
        client_address=""
        client_interface="eth0"
        listen_ip="0.0.0.0"
    elif [ "${console_kind}" == "spice" ] ; then
        client_address=""
        client_interface=""
        listen_ip="0.0.0.0"
    fi
    
    if [ -z "${client_address}" ] ; then
        if [ -z "${client_interface}" ] ; then
            # search for interface with default routing, if multiple default routes exist then select the one with the lowest metric.
            client_interface=$(route -n | awk '/^0.0.0.0/ { print $5 " " $NF }' | sort | awk '{ print $NF; exit }')
        fi
    
        # determine client ip dynamically based on interface provided
        client_address=$(ip a s $client_interface | grep 'inet ' | awk '{print $2}' | awk -F "/" '{print $1}' | head -n 1)
    fi
    
    if [ -z "${listen_ip}" ] ; then
        listen_ip=$client_address
    fi
    
    if [ "${console_kind}" == "novnc" ] ; then
    cat <<EOF>/tmp/pod-shared/nova-vnc.ini
    [vnc]
    vncserver_proxyclient_address = $client_address
    vncserver_listen = $listen_ip
    EOF
    elif [ "${console_kind}" == "spice" ] ; then
    cat <<EOF>/tmp/pod-shared/nova-spice.ini
    [spice]
    server_proxyclient_address = $client_address
    server_listen = $listen_ip
    EOF
    fi
    
  nova-console-proxy-init-assets.sh: |
    #!/bin/bash
    
    
    
    set -ex
    
    console_kind="novnc"
    if [ "${console_kind}" == "novnc" ] ; then
        cp -vaRf /usr/share/novnc/* /tmp/usr/share/novnc/
    elif [ "${console_kind}" == "spice" ] ; then
        cp -vaRf /usr/share/spice-html5/* /tmp/usr/share/spice-html5/
    fi
    
  ssh-start.sh: |
    #!/bin/bash
    
    
    
    set -ex
    
    IFS=','
    for KEY_TYPE in $KEY_TYPES; do
        KEY_PATH=/etc/ssh/ssh_host_${KEY_TYPE}_key
        if [[ ! -f "${KEY_PATH}" ]]; then
            ssh-keygen -q -t ${KEY_TYPE} -f ${KEY_PATH} -N ""
        fi
    done
    IFS=''
    
    mkdir -p ~nova/.ssh
    
    if [[ $(stat -c %U:%G ~nova/.ssh) != "nova:nova" ]]; then
        chown nova: ~nova/.ssh
    fi
    
    subnet_address="0.0.0.0/24"
    cat > /tmp/sshd_config_extend <<EOF
    
    # This Match block prevents Password Authentication for root user
    Match User root
        PasswordAuthentication no
    
    # This Match Block is used to allow Root Login exceptions over the
    # internal subnet used by Nova Migrations
    Match Address $subnet_address
        PermitRootLogin without-password
    EOF
    cat /tmp/sshd_config_extend >> /etc/ssh/sshd_config
    rm /tmp/sshd_config_extend
    
    exec /usr/sbin/sshd -D -e -o Port=$SSH_PORT
    
  cell-setup.sh: |
    #!/bin/bash
    
    
    
    set -ex
    
    NOVA_VERSION=$(nova-manage --version 2>&1 | grep -Eo '[0-9]+[.][0-9]+[.][0-9]+')
    
    # NOTE(portdirect): check if nova fully supports cells v2, and manage
    # accordingly. Support was complete in ocata (V14.x.x).
    
    if [ "${NOVA_VERSION%%.*}" -gt "14" ]; then
      nova-manage cell_v2 discover_hosts --verbose
    fi
    
  cell-setup-init.sh: |
    #!/bin/bash
    
    
    
    set -ex
    
    until openstack compute service list --service nova-compute -f value -c State | grep -q "^up$" ;do
      echo "Waiting for Nova Compute processes to register"
      sleep 10
    done
    
  nova-service-cleaner.sh: |
    #!/bin/bash
    
    
    
    set -xe
    
    NOVA_SERVICES_TO_CLEAN="$(openstack compute service list -f value -c Binary | sort | uniq | grep -v '^nova-compute$')"
    for NOVA_SERVICE in ${NOVA_SERVICES_TO_CLEAN}; do
      DEAD_SERVICE_IDS=$(openstack compute service list --service ${NOVA_SERVICE} -f json | jq -r '.[] | select(.State == "down") | .ID')
      for SERVICE_ID in ${DEAD_SERVICE_IDS}; do
        openstack compute service delete "${SERVICE_ID}"
      done
    done
    
  rabbit-init.sh: |    
    #!/bin/bash
    set -e
    # Extract connection details
    RABBIT_HOSTNAME=$(echo "${RABBITMQ_ADMIN_CONNECTION}" | \
      awk -F'[@]' '{print $2}' | \
      awk -F'[:/]' '{print $1}')
    RABBIT_PORT=$(echo "${RABBITMQ_ADMIN_CONNECTION}" | \
      awk -F'[@]' '{print $2}' | \
      awk -F'[:/]' '{print $2}')
    
    # Extract Admin User creadential
    RABBITMQ_ADMIN_USERNAME=$(echo "${RABBITMQ_ADMIN_CONNECTION}" | \
      awk -F'[@]' '{print $1}' | \
      awk -F'[//:]' '{print $4}')
    RABBITMQ_ADMIN_PASSWORD=$(echo "${RABBITMQ_ADMIN_CONNECTION}" | \
      awk -F'[@]' '{print $1}' | \
      awk -F'[//:]' '{print $5}')
    
    # Extract User creadential
    RABBITMQ_USERNAME=$(echo "${RABBITMQ_USER_CONNECTION}" | \
      awk -F'[@]' '{print $1}' | \
      awk -F'[//:]' '{print $4}')
    RABBITMQ_PASSWORD=$(echo "${RABBITMQ_USER_CONNECTION}" | \
      awk -F'[@]' '{print $1}' | \
      awk -F'[//:]' '{print $5}')
    
    # Extract User vHost
    RABBITMQ_VHOST=$(echo "${RABBITMQ_USER_CONNECTION}" | \
      awk -F'[@]' '{print $2}' | \
      awk -F'[:/]' '{print $3}')
    # Resolve vHost to / if no value is set
    RABBITMQ_VHOST="${RABBITMQ_VHOST:-/}"
    
    function rabbitmqadmin_cli () {
      rabbitmqadmin \
        --host="${RABBIT_HOSTNAME}" \
        --port="${RABBIT_PORT}" \
        --username="${RABBITMQ_ADMIN_USERNAME}" \
        --password="${RABBITMQ_ADMIN_PASSWORD}" \
        ${@}
    }
    
    echo "Managing: User: ${RABBITMQ_USERNAME}"
    rabbitmqadmin_cli \
      declare user \
      name="${RABBITMQ_USERNAME}" \
      password="${RABBITMQ_PASSWORD}" \
      tags="user"
    
    if [ "${RABBITMQ_VHOST}" != "/" ]
    then
      echo "Managing: vHost: ${RABBITMQ_VHOST}"
      rabbitmqadmin_cli \
        declare vhost \
        name="${RABBITMQ_VHOST}"
    else
      echo "Skipping root vHost declaration: vHost: ${RABBITMQ_VHOST}"
    fi
    
    echo "Managing: Permissions: ${RABBITMQ_USERNAME} on ${RABBITMQ_VHOST}"
    rabbitmqadmin_cli \
      declare permission \
      vhost="${RABBITMQ_VHOST}" \
      user="${RABBITMQ_USERNAME}" \
      configure=".*" \
      write=".*" \
      read=".*"
    
    if [ ! -z "$RABBITMQ_AUXILIARY_CONFIGURATION" ]
    then
      echo "Applying additional configuration"
      echo "${RABBITMQ_AUXILIARY_CONFIGURATION}" > /tmp/rmq_definitions.json
      rabbitmqadmin_cli import /tmp/rmq_definitions.json
    fi
  wait-for-computes-init.sh: |
    #!/bin/bash
    
    
    
    set -ex
    
    # This runs in a bootstrap init container. It counts the number of compute nodes.
    COMPUTE_NODES=$(kubectl get nodes -o custom-columns=NAME:.metadata.name --no-headers | sort)
    /bin/echo $COMPUTE_NODES > /tmp/compute_nodes.txt
